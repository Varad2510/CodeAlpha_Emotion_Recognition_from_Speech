{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn3mCZW8PZctjA5efj9t5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varad2510/CodeAlpha_Emotion_Recognition_from_Speech/blob/main/Emotion_Recognition_From_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "60G6dheEUKvl",
        "outputId": "69652cc2-8292-424b-92a9-ce00cadac474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Files extracted successfully!\n",
            "Extracted files: ['Actor_05', 'Actor_02', 'Actor_09', 'Actor_20', 'Actor_14', 'Actor_04', 'Actor_07', 'Actor_17', 'Actor_19', 'Actor_01', 'Actor_13', 'Actor_06', 'Actor_15', 'Actor_24', 'Actor_10', 'Actor_11', 'Actor_12', 'Actor_03', 'Actor_08', 'audio_speech_actors_01-24', 'Actor_23', 'Actor_21', 'Actor_18', 'Actor_22', 'Actor_16']\n",
            "Feature extraction completed!\n",
            "Training data shape: (1152, 40)\n",
            "Test data shape: (288, 40)\n",
            "Model summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m10,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m3,096\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,096</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,488\u001b[0m (181.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,488</span> (181.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,488\u001b[0m (181.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,488</span> (181.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0374 - loss: 67.2327 - val_accuracy: 0.0417 - val_loss: 3.1780\n",
            "Epoch 2/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0360 - loss: 6.4910 - val_accuracy: 0.0417 - val_loss: 3.1784\n",
            "Epoch 3/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0345 - loss: 3.4359 - val_accuracy: 0.0417 - val_loss: 3.1786\n",
            "Epoch 4/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0451 - loss: 3.3698 - val_accuracy: 0.0417 - val_loss: 3.1790\n",
            "Epoch 5/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0383 - loss: 3.3061 - val_accuracy: 0.0417 - val_loss: 3.1794\n",
            "Epoch 6/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0580 - loss: 3.2052 - val_accuracy: 0.0417 - val_loss: 3.1797\n",
            "Epoch 7/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0507 - loss: 3.3029 - val_accuracy: 0.0417 - val_loss: 3.1801\n",
            "Epoch 8/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0375 - loss: 3.2619 - val_accuracy: 0.0417 - val_loss: 3.1805\n",
            "Epoch 9/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0463 - loss: 3.2195 - val_accuracy: 0.0208 - val_loss: 3.1808\n",
            "Epoch 10/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0542 - loss: 3.1832 - val_accuracy: 0.0208 - val_loss: 3.1811\n",
            "Epoch 11/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0547 - loss: 3.2067 - val_accuracy: 0.0208 - val_loss: 3.1813\n",
            "Epoch 12/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0492 - loss: 3.1883 - val_accuracy: 0.0208 - val_loss: 3.1818\n",
            "Epoch 13/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0561 - loss: 3.1966 - val_accuracy: 0.0208 - val_loss: 3.1821\n",
            "Epoch 14/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0513 - loss: 3.2250 - val_accuracy: 0.0208 - val_loss: 3.1822\n",
            "Epoch 15/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0449 - loss: 3.1892 - val_accuracy: 0.0208 - val_loss: 3.1826\n",
            "Epoch 16/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0459 - loss: 3.2002 - val_accuracy: 0.0208 - val_loss: 3.1828\n",
            "Epoch 17/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0473 - loss: 3.1895 - val_accuracy: 0.0208 - val_loss: 3.1831\n",
            "Epoch 18/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0491 - loss: 3.1854 - val_accuracy: 0.0208 - val_loss: 3.1834\n",
            "Epoch 19/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0508 - loss: 3.1830 - val_accuracy: 0.0208 - val_loss: 3.1836\n",
            "Epoch 20/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0542 - loss: 3.1999 - val_accuracy: 0.0208 - val_loss: 3.1840\n",
            "Epoch 21/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0419 - loss: 3.1794 - val_accuracy: 0.0208 - val_loss: 3.1841\n",
            "Epoch 22/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0548 - loss: 3.1753 - val_accuracy: 0.0208 - val_loss: 3.1845\n",
            "Epoch 23/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0507 - loss: 3.1871 - val_accuracy: 0.0208 - val_loss: 3.1847\n",
            "Epoch 24/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0491 - loss: 3.1856 - val_accuracy: 0.0208 - val_loss: 3.1848\n",
            "Epoch 25/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0509 - loss: 3.1807 - val_accuracy: 0.0208 - val_loss: 3.1851\n",
            "Epoch 26/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0458 - loss: 3.1856 - val_accuracy: 0.0208 - val_loss: 3.1853\n",
            "Epoch 27/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0432 - loss: 3.1738 - val_accuracy: 0.0208 - val_loss: 3.1855\n",
            "Epoch 28/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0356 - loss: 3.1828 - val_accuracy: 0.0208 - val_loss: 3.1856\n",
            "Epoch 29/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0450 - loss: 3.1729 - val_accuracy: 0.0208 - val_loss: 3.1857\n",
            "Epoch 30/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0512 - loss: 3.1839 - val_accuracy: 0.0208 - val_loss: 3.1858\n",
            "Epoch 31/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0415 - loss: 3.1733 - val_accuracy: 0.0208 - val_loss: 3.1861\n",
            "Epoch 32/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0480 - loss: 3.1845 - val_accuracy: 0.0208 - val_loss: 3.1863\n",
            "Epoch 33/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0479 - loss: 3.1753 - val_accuracy: 0.0208 - val_loss: 3.1865\n",
            "Epoch 34/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0510 - loss: 3.1778 - val_accuracy: 0.0208 - val_loss: 3.1866\n",
            "Epoch 35/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0333 - loss: 3.1767 - val_accuracy: 0.0208 - val_loss: 3.1866\n",
            "Epoch 36/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0349 - loss: 3.1802 - val_accuracy: 0.0208 - val_loss: 3.1868\n",
            "Epoch 37/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0526 - loss: 3.1777 - val_accuracy: 0.0208 - val_loss: 3.1870\n",
            "Epoch 38/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0358 - loss: 3.1790 - val_accuracy: 0.0208 - val_loss: 3.1871\n",
            "Epoch 39/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0527 - loss: 3.1775 - val_accuracy: 0.0208 - val_loss: 3.1873\n",
            "Epoch 40/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0490 - loss: 3.1810 - val_accuracy: 0.0208 - val_loss: 3.1873\n",
            "Epoch 41/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0441 - loss: 3.1785 - val_accuracy: 0.0208 - val_loss: 3.1874\n",
            "Epoch 42/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0550 - loss: 3.1767 - val_accuracy: 0.0208 - val_loss: 3.1876\n",
            "Epoch 43/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0409 - loss: 3.1791 - val_accuracy: 0.0208 - val_loss: 3.1878\n",
            "Epoch 44/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0393 - loss: 3.1785 - val_accuracy: 0.0208 - val_loss: 3.1878\n",
            "Epoch 45/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0430 - loss: 3.1785 - val_accuracy: 0.0208 - val_loss: 3.1879\n",
            "Epoch 46/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0501 - loss: 3.1800 - val_accuracy: 0.0208 - val_loss: 3.1879\n",
            "Epoch 47/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0421 - loss: 3.1819 - val_accuracy: 0.0208 - val_loss: 3.1879\n",
            "Epoch 48/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0523 - loss: 3.1762 - val_accuracy: 0.0208 - val_loss: 3.1881\n",
            "Epoch 49/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0576 - loss: 3.1765 - val_accuracy: 0.0208 - val_loss: 3.1882\n",
            "Epoch 50/50\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0365 - loss: 3.1759 - val_accuracy: 0.0208 - val_loss: 3.1883\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "\n",
            "Classification Report:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Actor_01       0.00      0.00      0.00        16\n",
            "    Actor_02       0.00      0.00      0.00        13\n",
            "    Actor_03       0.00      0.00      0.00        12\n",
            "    Actor_04       0.00      0.00      0.00        12\n",
            "    Actor_05       0.00      0.00      0.00        11\n",
            "    Actor_06       0.00      0.00      0.00        10\n",
            "    Actor_07       0.00      0.00      0.00        14\n",
            "    Actor_08       0.00      0.00      0.00        13\n",
            "    Actor_09       0.02      1.00      0.04         6\n",
            "    Actor_10       0.00      0.00      0.00        12\n",
            "    Actor_11       0.00      0.00      0.00        15\n",
            "    Actor_12       0.00      0.00      0.00        10\n",
            "    Actor_13       0.00      0.00      0.00        16\n",
            "    Actor_14       0.00      0.00      0.00        14\n",
            "    Actor_15       0.00      0.00      0.00        13\n",
            "    Actor_16       0.00      0.00      0.00        17\n",
            "    Actor_17       0.00      0.00      0.00         9\n",
            "    Actor_18       0.00      0.00      0.00        10\n",
            "    Actor_19       0.00      0.00      0.00        10\n",
            "    Actor_20       0.00      0.00      0.00        12\n",
            "    Actor_21       0.00      0.00      0.00        11\n",
            "    Actor_22       0.00      0.00      0.00        10\n",
            "    Actor_23       0.00      0.00      0.00        10\n",
            "    Actor_24       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.02       288\n",
            "   macro avg       0.00      0.04      0.00       288\n",
            "weighted avg       0.00      0.02      0.00       288\n",
            "\n",
            "Model saved successfully to Google Drive!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define Dataset Path\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "DATASET_PATH = '/content/drive/My Drive/Speech Emotion Dataset/Speech_emotion_dataset.zip.zip'\n",
        "\n",
        "# Step 3: Extract Dataset\n",
        "extract_path = '/content/SpeechEmotionDataset'\n",
        "\n",
        "with zipfile.ZipFile(DATASET_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Files extracted successfully!\")\n",
        "print(\"Extracted files:\", os.listdir(extract_path))\n",
        "\n",
        "# Step 4: Import Necessary Libraries\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 5: Data Preprocessing\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        # Load the audio file without resampling\n",
        "        audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # Extract MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "\n",
        "        # Return the mean of the MFCCs\n",
        "        return np.mean(mfccs.T, axis=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Prepare Dataset\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for folder in os.listdir(extract_path):\n",
        "    folder_path = os.path.join(extract_path, folder)\n",
        "    if os.path.isdir(folder_path):  # Check if it's a folder\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            if file_path.endswith('.wav'):\n",
        "                try:\n",
        "                    data = extract_features(file_path)\n",
        "                    if data is not None:  # Only append if features are extracted successfully\n",
        "                        features.append(data)\n",
        "                        labels.append(folder)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "print(\"Feature extraction completed!\")\n",
        "\n",
        "# Step 6: Encode Labels and Split Data\n",
        "X = np.array(features)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(labels)\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")\n",
        "\n",
        "# Step 7: Build the Model\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Model summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Step 8: Train the Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
        "\n",
        "# Step 9: Evaluate the Model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_labels, y_pred_labels, target_names=label_encoder.classes_))\n",
        "\n",
        "# Step 10: Save the Model\n",
        "model.save('/content/drive/My Drive/SpeechEmotionModel.h5')\n",
        "print(\"Model saved successfully to Google Drive!\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}